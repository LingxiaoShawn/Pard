train:
  precision: 'bf16-mixed' # grid is too large to fit in fp32
  epochs: 1000
  batch_size: 1
  lr: 0.0002
  lr_patience: 150
  lr_warmup: 0
  lr_scheduler: 'plateau'
model:
  hidden_size: 96
  edge_hidden: 16                
  num_layers: 6
  norm: 'ln' 
  input_residual: True
  add_transpose: True
  use_relative_blockid: True
  use_absolute_blockid: False
  batched_sequential: True
diffusion:
  max_hops: 1
  num_steps: 50 
  noise_schedule_type: 'cosine'
  ce_only: False 
  ce_coeff: 0.1
  uniform_noise: False    
  blockwise_time: False    
  combine_training: False 